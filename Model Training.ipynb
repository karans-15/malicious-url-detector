{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProcessedDataFrame(filepath):\n",
    "    dataset = arff.loadarff(filepath)\n",
    "    df = pd.DataFrame(dataset[0])\n",
    "    str_df = df.select_dtypes([np.object]) \n",
    "    str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "\n",
    "    for col in str_df.columns:\n",
    "        str_df[col] = str_df[col].astype(int)\n",
    "    return str_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_training = getProcessedDataFrame(\"Training Dataset.arff\")\n",
    "print(complete_training.columns)\n",
    "\n",
    "#We will not include: SSLfinal_State,Domain_registration_length,port,Abnormal_URL,Redirect,popUpWindow,Google_Index,Links_pointing_to_page,Statistical_report\n",
    "reduced_df = complete_training[['having_IP_Address', 'URL_Length', 'Shortining_Service',\n",
    "       'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix',\n",
    "       'having_Sub_Domain','Favicon', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor',\n",
    "       'Links_in_tags', 'SFH', 'Submitting_to_email','on_mouseover', 'RightClick', 'Iframe',\n",
    "       'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank','Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_training['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-happening",
   "metadata": {},
   "source": [
    "## Metrics to evaluate this Project:\n",
    "\n",
    "Because the data we have is balanced (around 55:45%) we will consider ACCURACY as our major metric. We will also have to ensure that we will have a minimal TYPE ONE error (Minimize false positives)(FPR). \n",
    "This is because it is important that the user does not enter an unsafe url. We can tradeoff classifying a safe url as unsafe for the same reason as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We encode the data into positive values as our algorithms work better then\n",
    "def convertEncodingToPositive(dataframe):\n",
    "\n",
    "    mapping = {-1: 2, 0: 0, 1: 1}\n",
    "\n",
    "    col_map = {}\n",
    "\n",
    "    for col in dataframe:\n",
    "        col_map[col] = mapping\n",
    "\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        for j in range(dataframe.shape[1]):\n",
    "            dataframe.loc[i][j] = mapping[dataframe.loc[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertEncodingToPositive(reduced_df)\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = reduced_df.iloc[:,0:21]\n",
    "y_reduced = reduced_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits data into training and test data\n",
    "#Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced, y_reduced, test_size=0.2, random_state=7, stratify=y_reduced)\n",
    "\n",
    "print(type(X_train_red))\n",
    "print(X_train_red.shape)\n",
    "print(X_test_red.shape)\n",
    "print(y_train_red.shape)\n",
    "print(y_test_red.shape,\"\\n\")\n",
    "X_train_red = X_train_red.to_numpy()\n",
    "X_test_red = X_test_red.to_numpy()\n",
    "y_train_red = y_train_red.to_numpy()\n",
    "y_test_red = y_test_red.to_numpy()\n",
    "\n",
    "print(type(X_train_red))\n",
    "print(X_train_red.shape)\n",
    "print(X_test_red.shape)\n",
    "print(y_train_red.shape)\n",
    "print(y_test_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the training and test data, we will have a 5fold spilt for cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kf.split(X_train_red):\n",
    "    print(X_train_red[train].shape, y_train_red[train].shape, X_train_red[test].shape, y_train_red[test].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix assesses the performance of a classification model (F score types) (Precision and recall)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_val, y_pred):\n",
    "    labels = [1, 0]\n",
    "    cm = confusion_matrix(y_val, y_pred, labels)\n",
    "    # print(cm)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "#tp=true positive, fn=false negative, fp=false positive, tn=true negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_train_red_onehot = encoder.fit_transform(X_train_red)\n",
    "X_test_red_onehot = encoder.transform(X_test_red)\n",
    "pickle.dump(encoder, open(\"One_Hot_Encoder\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-decade",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_use_GNB(X_train_red, y_train_red):\n",
    "    \n",
    "    #These will store values for the accuracy scores\n",
    "    accuracy_scores_catNB = []\n",
    "    \n",
    "    #Do this for all n splits\n",
    "    for train, val in kf.split(X_train_red):\n",
    "        \n",
    "        clf_NB = CategoricalNB()\n",
    "        \n",
    "        #Train Model\n",
    "        clf_NB = clf_NB.fit(X_train_red[train], y_train_red[train])\n",
    "        \n",
    "        #Using validation data to predict\n",
    "        predictions = clf_NB.predict(X_train_red[val])\n",
    "        tp, fn, fp, tn = metrics.confusion_matrix(y_train_red[val], predictions).ravel()\n",
    "        accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        f1 = 2*precision*recall/(precision + recall)\n",
    "        accuracy_scores_catNB.append((accuracy, precision, recall, fpr, f1))\n",
    "\n",
    "    return np.mean(accuracy_scores_catNB, axis=0)\n",
    "\n",
    "metric_GNB = to_use_GNB(X_train_red_onehot, y_train_red)\n",
    "print(metric_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-baptist",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_KNN(X_train_red_onehot, y_train_red):\n",
    "    clf_knn = KNeighborsClassifier()\n",
    "    knn_param_grid = {\n",
    "      \"n_neighbors\": [3, 5, 7, 9, 15],\n",
    "      \"metric\": ['euclidean', 'manhattan']\n",
    "    }\n",
    "\n",
    "    gs_knn = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv = 3)\n",
    "    gs_results = gs_knn.fit(X_train_red_onehot, y_train_red)\n",
    "\n",
    "    return gs_results.best_params_\n",
    "\n",
    "bestparams_knn = gridsearch_KNN(X_train_red_onehot, y_train_red)\n",
    "print(bestparams_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_use_KNN(X_train_red, y_train_red):\n",
    "    accuracy_scores_catKNN = []\n",
    "    for train, val in kf.split(X_train_red):\n",
    "        \n",
    "        clf_neigh = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "        \n",
    "        #Train model\n",
    "        clf_neigh = clf_neigh.fit(X_train_red[train], y_train_red[train])\n",
    "        \n",
    "        #Make predictions\n",
    "        predictions = clf_neigh.predict(X_train_red[val])\n",
    "        tp, fn, fp, tn = metrics.confusion_matrix(y_train_red[val], predictions).ravel()\n",
    "        accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        f1 = 2*precision*recall/(precision + recall)\n",
    "        accuracy_scores_catKNN.append((accuracy, precision, recall, fpr, f1))\n",
    "  \n",
    "    return np.mean(accuracy_scores_catKNN, axis=0)\n",
    "\n",
    "metric_KNN = to_use_KNN(X_train_red_onehot, y_train_red)\n",
    "print(metric_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-decade",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_use_XGB(X_train_red, y_train_red):\n",
    "    accuracy_scores_xgb = []\n",
    "    for train, val in kf.split(X_train_red):\n",
    "        \n",
    "        \n",
    "        clf_xgb = XGBClassifier(silent=False, \n",
    "                        scale_pos_weight=1,\n",
    "                        learning_rate=0.01,  \n",
    "                        colsample_bytree = 0.4,\n",
    "                        subsample = 0.8,\n",
    "                        objective='binary:logistic', \n",
    "                        n_estimators=1000, \n",
    "                        reg_alpha = 0.3,\n",
    "                        max_depth=4, \n",
    "                        gamma=10)\n",
    "        \n",
    "        #Train Model\n",
    "        clf_xgb = clf_xgb.fit(X_train_red[train], y_train_red[train])\n",
    "        \n",
    "        #Predict\n",
    "        predictions = clf_xgb.predict(X_train_red[val])\n",
    "        \n",
    "        tp, fn, fp, tn = metrics.confusion_matrix(y_train_red[val], predictions).ravel()\n",
    "        accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        f1 = 2*precision*recall/(precision + recall)\n",
    "        accuracy_scores_xgb.append((accuracy, precision, recall, fpr, f1))\n",
    "\n",
    "    return np.mean(accuracy_scores_xgb, axis=0)\n",
    "    \n",
    "metric_xgb = to_use_XGB(X_train_red_onehot, y_train_red)\n",
    "print(metric_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-camcorder",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_decision_tree(X_train_red, y_train_red):\n",
    "    dt = DecisionTreeClassifier(random_state=5)\n",
    "    p = {\"max_depth\": range(1,20), \"random_state\":[5]}\n",
    "    gs = GridSearchCV(estimator=dt,param_grid=p)\n",
    "    gs_fit = gs.fit(X_train_red, y_train_red)\n",
    "    return gs_fit.best_params_\n",
    "\n",
    "best_params_decision_tree = grid_search_decision_tree(X_train_red_onehot, y_train_red)\n",
    "print(best_params_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_use_decisiontree(X_train_red, y_train_red):\n",
    "    accuracy_scores_dt = []\n",
    "    for train, val in kf.split(X_train_red):\n",
    "        dt = DecisionTreeClassifier(random_state=5, max_depth=18)\n",
    "        dt = dt.fit(X_train_red[train], y_train_red[train])\n",
    "        tp, fn, fp, tn = metrics.confusion_matrix(y_train_red[val],dt.predict(X_train_red[val])).ravel()\n",
    "        dt_accuracy = (tn+tp)/(tp+tn+fp+fn)\n",
    "        dt_prec = tp/(tp+fp)\n",
    "        dt_rec = tp/(tp+fn)\n",
    "        dt_fpr = fp/(fp+tn)\n",
    "        dt_f1 = 2*dt_prec*dt_rec/(dt_prec+dt_rec)\n",
    "        accuracy_scores_dt.append((dt_accuracy,dt_prec,dt_rec,dt_fpr,dt_f1))\n",
    "  \n",
    "    return np.mean(accuracy_scores_dt,axis=0)\n",
    "\n",
    "metric_decision_tree = to_use_decisiontree(X_train_red_onehot, y_train_red)\n",
    "print(metric_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-transcript",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_random_forest(X_train_red_onehot, y_train_red):\n",
    "    rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "    param_grid = { \n",
    "      'n_estimators': [200, 700],\n",
    "      'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    CV_rfc.fit(X_train_red, y_train_red)\n",
    "    return CV_rfc.best_params_\n",
    "\n",
    "best_params_rfc = grid_search_random_forest(X_train_red_onehot, y_train_red)\n",
    "print(best_params_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_use_rfc(X_train_red_onehot, y_train_red):\n",
    "    accuracy_scores_forest = []\n",
    "    for train, val in kf.split(X_train_red):\n",
    "        rforest = RandomForestClassifier(max_features= 'auto' ,n_estimators=200)\n",
    "        rforest = rforest.fit(X_train_red_onehot[train],y_train_red[train])\n",
    "        tp1, fn1, fp1, tn1 = metrics.confusion_matrix(y_train_red[val],rforest.predict(X_train_red_onehot[val])).ravel()\n",
    "        r_accuracy = (tn1 + tp1)/(tn1+tp1+fn1+fp1)\n",
    "        r_prec = tp1/(tp1+fp1)\n",
    "        r_rec = tp1/(tp1+fn1)\n",
    "        r_fpr = fp1/(fp1+tn1)\n",
    "        r_f1 = 2*(r_prec)*r_rec/(r_prec+r_rec)\n",
    "        accuracy_scores_forest.append((r_accuracy,r_prec,r_rec,r_fpr,r_f1))\n",
    "\n",
    "    return np.mean(accuracy_scores_forest, axis=0)\n",
    "  \n",
    "\n",
    "metric_rforest = to_use_rfc(X_train_red_onehot, y_train_red)\n",
    "print(metric_rforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-syria",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_svm(X_train_red_onehot, y_train_red):\n",
    "    svm_clf = svm.SVC()\n",
    "    param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "                'gamma': [1, 0.1, 0.01, 0.001], \n",
    "                'kernel': ['rbf', 'linear']}  \n",
    "\n",
    "    gs_svm = GridSearchCV(svm.SVC(), param_grid, cv = 3)\n",
    "    gs_results = gs_svm.fit(X_train_red_onehot, y_train_red)\n",
    "\n",
    "    return gs_results.best_params_\n",
    "\n",
    "bestparams_svm = grid_search_svm(X_train_red_onehot, y_train_red)\n",
    "print(bestparams_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_use_SVM(X_train_red_onehot, y_train_red):\n",
    "    accuracy_scores_svm = []\n",
    "    for train, val in kf.split(X_train_red_onehot):\n",
    "        svm_clf = svm.SVC(kernel='rbf', gamma = 0.1, C = 10, probability=True)\n",
    "        svm_clf = svm_clf.fit(X_train_red_onehot[train], y_train_red[train])\n",
    "        tp, fn, fp, tn = metrics.confusion_matrix(y_train_red[val], svm_clf.predict(X_train_red_onehot[val])).ravel()\n",
    "        plot_cm(y_train_red[val], svm_clf.predict(X_train_red_onehot[val]))\n",
    "    \n",
    "        accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        f1 = 2*precision*recall/(precision + recall)\n",
    "        accuracy_scores_svm.append((accuracy, precision, recall, fpr, f1))\n",
    "\n",
    "\n",
    "    return np.mean(accuracy_scores_svm, axis=0)\n",
    "\n",
    "metric_svm = to_use_SVM(X_train_red_onehot, y_train_red)\n",
    "print(metric_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\t===============================================Training Metrics===============================================\\n\")\n",
    "labels = [\"Accuracy: \", \"Precision: \", \"Recall: \", \"FPR: \", \"F1: \"]\n",
    "\n",
    "print(\"Naive Bayes\\n\")\n",
    "for i in range(len(metric_GNB)):\n",
    "    print(labels[i],metric_GNB[i])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"KNN\\n\")\n",
    "for i in range(len(metric_KNN)):\n",
    "    print(labels[i],metric_KNN[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"XGBoost\\n\")\n",
    "for i in range(len(metric_xgb)):\n",
    "    print(labels[i],metric_xgb[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Decision Trees\\n\")\n",
    "for i in range(len(metric_decision_tree)):\n",
    "    print(labels[i],metric_decision_tree[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Random Forest\\n\")\n",
    "for i in range(len(metric_rforest)):\n",
    "    print(labels[i],metric_rforest[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Support Vector Machines\\n\")\n",
    "for i in range(len(metric_svm)):\n",
    "    print(labels[i],metric_svm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "def to_test_KNN(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red):\n",
    "    accuracy_scores_catKNN = []\n",
    "        \n",
    "    clf_neigh = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "\n",
    "    #Train model\n",
    "    clf_neigh = clf_neigh.fit(X_train_red_onehot, y_train_red)\n",
    "\n",
    "    #Make predictions\n",
    "    predictions = clf_neigh.predict(X_test_red_onehot)\n",
    "    tp, fn, fp, tn = metrics.confusion_matrix(y_test_red, predictions).ravel()\n",
    "    accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    f1 = 2*precision*recall/(precision + recall)\n",
    "    accuracy_scores_catKNN.append((accuracy, precision, recall, fpr, f1))\n",
    "    \n",
    "    plot_confusion_matrix(clf_neigh , X_test_red_onehot, y_test_red)\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy_scores_catKNN\n",
    "\n",
    "test_accuracy_knn = to_test_KNN(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red)\n",
    "\n",
    "\n",
    "def to_test_XGB(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red):\n",
    "    accuracy_scores_xgb = []\n",
    "    clf_xgb = XGBClassifier(silent=False, scale_pos_weight=1,learning_rate=0.01, colsample_bytree = 0.4,subsample = 0.8, objective='binary:logistic',  n_estimators=1000, reg_alpha = 0.3,max_depth=4, gamma=10)\n",
    "\n",
    "    #Train Model\n",
    "    clf_xgb = clf_xgb.fit(X_train_red_onehot, y_train_red)\n",
    "\n",
    "\n",
    "    tp, fn, fp, tn = metrics.confusion_matrix(y_test_red, clf_xgb.predict(X_test_red_onehot)).ravel()\n",
    "    accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    f1 = 2*precision*recall/(precision + recall)\n",
    "    accuracy_scores_xgb.append((accuracy, precision, recall, fpr, f1))\n",
    "    plot_confusion_matrix(clf_xgb , X_test_red_onehot, y_test_red)\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy_scores_xgb \n",
    "\n",
    "test_accuracy_xgb = to_test_XGB(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red)\n",
    "\n",
    "def to_test_decisiontree(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red):\n",
    "    accuracy_scores_dt = []\n",
    "    dt = DecisionTreeClassifier(random_state=5, max_depth=18)\n",
    "    dt = dt.fit(X_train_red_onehot, y_train_red)\n",
    "    tp, fn, fp, tn = metrics.confusion_matrix(y_test_red,dt.predict(X_test_red_onehot)).ravel()\n",
    "    dt_accuracy = (tn+tp)/(tp+tn+fp+fn)\n",
    "    dt_prec = tp/(tp+fp)\n",
    "    dt_rec = tp/(tp+fn)\n",
    "    dt_fpr = fp/(fp+tn)\n",
    "    dt_f1 = 2*dt_prec*dt_rec/(dt_prec+dt_rec)\n",
    "    accuracy_scores_dt.append((dt_accuracy,dt_prec,dt_rec,dt_fpr,dt_f1))\n",
    "    plot_confusion_matrix(dt, X_test_red_onehot, y_test_red)\n",
    "    plt.show()\n",
    "  \n",
    "    return accuracy_scores_dt\n",
    "\n",
    "test_accuracy_dt = to_test_decisiontree(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red)\n",
    "\n",
    "def to_test_rfc(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red):\n",
    "    \n",
    "    accuracy_scores_rfc = []\n",
    "    rforest = RandomForestClassifier(max_features= 'sqrt' ,n_estimators=200)\n",
    "    rforest = rforest.fit(X_train_red_onehot,y_train_red)\n",
    "    tp, fn, fp, tn = metrics.confusion_matrix(y_test_red, rforest.predict(X_test_red_onehot)).ravel()\n",
    "    accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    f1 = 2*precision*recall/(precision + recall)\n",
    "    accuracy_scores_rfc.append((accuracy, precision, recall, fpr, f1))\n",
    "    pickle.dump(rforest, open(\"RF_Final_Model.pkl\", 'wb'))\n",
    "    plot_confusion_matrix(rforest , X_test_red_onehot, y_test_red)\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy_scores_rfc\n",
    "  \n",
    "\n",
    "test_accuracy_rfc = to_test_rfc(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red)\n",
    "\n",
    "\n",
    "def to_test_SVM(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red):\n",
    "    accuracy_scores_svm = []\n",
    "    svm_clf = svm.SVC(kernel='rbf', gamma = 0.1, C = 10, probability=True)\n",
    "    svm_clf = svm_clf.fit(X_train_red_onehot, y_train_red)\n",
    "    tp, fn, fp, tn = metrics.confusion_matrix(y_test_red, svm_clf.predict(X_test_red_onehot)).ravel()\n",
    "    accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    f1 = 2*precision*recall/(precision + recall)\n",
    "    pickle.dump(svm_clf, open(\"SVM_Final_Model.pkl\", 'wb'))\n",
    "    accuracy_scores_svm.append((accuracy, precision, recall, fpr, f1))\n",
    "    plot_confusion_matrix(svm_clf , X_test_red_onehot, y_test_red)\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy_scores_svm\n",
    "\n",
    "test_accuracy_svm = to_test_SVM(X_test_red_onehot, y_test_red, X_train_red_onehot, y_train_red)\n",
    "\n",
    "\n",
    "print(\"\\t==============================================Testing Metrics==================================================\\n\")\n",
    "\n",
    "print(\"KNN: \\n\",test_accuracy_knn)\n",
    "\n",
    "print(\"XGBoost: \\n\",test_accuracy_xgb)\n",
    "\n",
    "print(\"Decision Tree: \\n\",test_accuracy_dt)\n",
    "\n",
    "print(\"Random Forest: \\n\",test_accuracy_rfc)\n",
    "\n",
    "print(\"Support Vector Machines: \\n\",test_accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dt = 'SVM_Final_Model.pkl'\n",
    "loaded_model = pickle.load(open(filename_dt, 'rb'))\n",
    "tp, fn, fp, tn = metrics.confusion_matrix(y_train_red, loaded_model.predict(X_train_red_onehot)).ravel()\n",
    "accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "recall = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "print(accuracy)\n",
    "print(recall)\n",
    "print(fpr,\"\\n\\n\")\n",
    "\n",
    "filename_dt = 'RF_Final_Model.pkl'\n",
    "loaded_model = pickle.load(open(filename_dt, 'rb'))\n",
    "tp, fn, fp, tn = metrics.confusion_matrix(y_train_red, loaded_model.predict(X_train_red_onehot)).ravel()\n",
    "accuracy = (tn+tp)/(fp+fn+tp+tn)\n",
    "recall = tp/(tp+fn)\n",
    "fpr = fp/(fp+tn)\n",
    "print(accuracy)\n",
    "print(recall)\n",
    "print(fpr,\"\\n\")\n",
    "\n",
    "print(\"Random Forest performs best with least no of false positives and high accuracy and recall, hence we will go forward with this algorithm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne_analysis():\n",
    "    \"\"\" For TSNE analysis on the training dataset with \n",
    "    last hidden layer output\"\"\"\n",
    "\n",
    "    filename_dt = 'RF_Final_Model'\n",
    "    loaded_model = pickle.load(open(filename_dt, 'rb'))\n",
    "  \n",
    "    hidden_opt = loaded_model.predict_proba(X_train_red_onehot)\n",
    "    df = pd.DataFrame(hidden_opt)\n",
    "    df['y'] = y_train_red\n",
    "    df['label'] = df['y'].apply(lambda i: str(i))\n",
    "    tsne = TSNE(n_components = 2, perplexity = 50, verbose = 1, n_iter = 1000)\n",
    "    tsne_res = tsne.fit_transform(hidden_opt)\n",
    "\n",
    "    df['TSNE 1st component'] = tsne_res[:,0]\n",
    "    df['TSNE 2nd component'] = tsne_res[:,1]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x = \"TSNE 1st component\", y = \"TSNE 2nd component\",\n",
    "        hue = 'y',\n",
    "        palette = sns.color_palette(\"hls\", 2),\n",
    "        data = df,\n",
    "        legend = \"full\",\n",
    "        alpha = 0.3\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "tsne_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
